{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01b4da99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Any, Dict, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8d76bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(ele: List[Any]) -> float:\n",
    "    \"\"\"计算列表的信息熵 (Empirical Entropy)\n",
    "\n",
    "    [cite_start]对应书中代码清单 7-1 [cite: 77] [cite_start]及公式 (7-2) [cite: 45]。\n",
    "    熵的计算公式：E(D) = -sum(p_k * log2(p_k))\n",
    "\n",
    "    Args:\n",
    "        ele (List[Any]): 包含类别取值的列表 (例如: ['是', '否', '是', ...])\n",
    "\n",
    "    Returns:\n",
    "        float: 信息熵值。\n",
    "               如果列表为空或所有元素相同，熵应为 0。\n",
    "    \"\"\"\n",
    "    # 1. 计算概率分布\n",
    "    # set(ele) 获取唯一元素，count() 计算频次，除以总长度得到概率 P(x)\n",
    "    probs = [ele.count(i)/len(ele) for i in set(ele)]\n",
    "\n",
    "    # 2. 应用香农熵公式\n",
    "    # H(x) = - Σ p(x) * log2(p(x))\n",
    "    entropy = - np.sum([prob * np.log2(prob) for prob in probs])\n",
    "\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39f93289",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_split(df: pd.DataFrame, col: str) -> Dict[Any, pd.DataFrame]:\n",
    "    \"\"\"根据指定特征的取值划分数据集\n",
    "\n",
    "    [cite_start]对应书中代码清单 7-5 [cite: 202]。\n",
    "    ID3 算法会对特征的每一个唯一取值建立一个分支。\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): 待划分的训练数据 DataFrame。\n",
    "        col (str): 划分数据的依据特征列名。\n",
    "\n",
    "    Returns:\n",
    "        Dict[Any, pd.DataFrame]: 划分后的数据字典。\n",
    "            键 (Key): 特征的某个取值。\n",
    "            值 (Value): 该特征取值为 Key 的数据子集 DataFrame。\n",
    "    \"\"\"\n",
    "    unique_value = df[col].unique()\n",
    "    res_dict = {}\n",
    "    for key in unique_value:\n",
    "        res_dict[key] = df[df[col] == key]\n",
    "    return res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e04c226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_best_feature(df: pd.DataFrame, label: str) -> Tuple[float, str, Dict[Any, pd.DataFrame]]:\n",
    "    \"\"\"根据信息增益选择最优特征\n",
    "\n",
    "    计算公式：信息增益 g(D, A) = H(D) - H(D|A)\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): 当前节点的训练数据。\n",
    "        label (str): 标签列的名称 (Target variable)。\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, str, Dict]: 返回一个元组，包含：\n",
    "            - max_value (float): 最大的信息增益值。\n",
    "            - best_col (str): 信息增益最大的特征名称。\n",
    "            - max_splited (Dict): 根据最优特征划分后的数据字典 (复用 df_split 的结果)。\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. 计算整个数据集 D 的经验熵 H(D)\n",
    "    entropy_d = entropy(df[label].tolist())\n",
    "\n",
    "    ig = {}\n",
    "    splited_dict = {}\n",
    "    # 2. 遍历每一个特征列\n",
    "    for key, _ in df.items():\n",
    "        # 跳过标签列\n",
    "        if key == label:\n",
    "            continue\n",
    "        col_entropy = []\n",
    "        p = []\n",
    "\n",
    "        # a. 使用 df_split 划分数据\n",
    "        splited_dict[key] = df_split(df, key)\n",
    "        for value in splited_dict[key].values():\n",
    "            col_entropy.append(entropy(value['play'].tolist()))\n",
    "            p.append(len(value)/len(df))\n",
    "        # b. 计算经验条件熵和信息增益\n",
    "        ig[key] = entropy_d - np.sum(np.array([p]) * np.array([col_entropy]))\n",
    "\n",
    "    # 4. 记录并返回增益最大的那个特征及其相关信息\n",
    "    if len(ig) != 0:\n",
    "        best_col = max(ig, key=ig.get)\n",
    "        max_value = ig[best_col]\n",
    "        max_splited = splited_dict[best_col]\n",
    "    else:\n",
    "        best_col = None\n",
    "        max_value = None\n",
    "        max_splited = None\n",
    "\n",
    "    return max_value, best_col, max_splited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c421bb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3Tree:\n",
    "    # 定义决策树结点类 [cite: 263]\n",
    "    class TreeNode:\n",
    "        def __init__(self, name):\n",
    "            \"\"\"\n",
    "            初始化树结点\n",
    "\n",
    "            Args:\n",
    "                name: 结点名称（如果是内部结点，则是特征名；如果是叶子结点，则是分类结果）\n",
    "            \"\"\"\n",
    "            # 1. 记录结点名字\n",
    "            self.name = name\n",
    "            # 2. 初始化连接字典 (connections)，用于存储子结点\n",
    "            #    格式：{label: node}，其中 label 是特征取值 (如 '晴')，node 是对应的子结点对象\n",
    "            self.connections = {}\n",
    "\n",
    "        def connect(self, label, node):\n",
    "            \"\"\"\n",
    "            建立当前结点与子结点的连接\n",
    "\n",
    "            Args:\n",
    "                label: 边上的标签（特征的取值，如 '晴'）\n",
    "                node: 连接的子结点对象\n",
    "            \"\"\"\n",
    "            # 将 label 和 node 存入 connections 字典\n",
    "            self.connections[label] = node\n",
    "\n",
    "\n",
    "    def __init__(self, df, label):\n",
    "        \"\"\"\n",
    "        初始化 ID3 算法实例\n",
    "\n",
    "        Args:\n",
    "            df: 训练数据集\n",
    "            label: 目标标签列名 (如 'play')\n",
    "        \"\"\"\n",
    "        # 1. 保存 columns (特征列表，排除 label)\n",
    "        self.columns = df.columns\n",
    "        # 2. 保存 df 和 label\n",
    "        self.df = df\n",
    "        self.label = label\n",
    "        # 3. 创建根结点 (self.root)，命名为 'Root'\n",
    "        self.root = self.TreeNode(\"Root\")\n",
    "\n",
    "    def construct_tree(self):\n",
    "        \"\"\"\n",
    "        开始构建决策树（对外调用的接口）\n",
    "        \"\"\"\n",
    "        # 调用下面的递归函数 construct\n",
    "        # 传入参数：当前父结点(self.root), 边标签(''), 数据集(self.df), 特征列表(self.columns)\n",
    "        self.construct(self.root, '', self.df, self.columns)\n",
    "\n",
    "    def construct(self, parent_node, parent_label, sub_df, columns):\n",
    "        \"\"\"\n",
    "        递归构建决策树的核心逻辑 [cite: 284]\n",
    "\n",
    "        Args:\n",
    "            parent_node: 父结点对象\n",
    "            parent_label: 指向当前结点的边标签（即父结点特征的某个取值）\n",
    "            sub_df: 当前分支的数据子集\n",
    "            columns: 当前可用的特征列表\n",
    "        \"\"\"\n",
    "        # 1. 调用 choose_best_feature 选择最优特征\n",
    "        max_value, best_col, max_splited = choose_best_feature(sub_df[columns], self.label)\n",
    "\n",
    "        # 2. 处理特殊情况（递归停止条件）：\n",
    "        # 如果选不到特征（best_feature 为空），或者数据纯度已经很高：\n",
    "        if best_col is None:\n",
    "            # -> 创建一个叶子结点（取 sub_df 中数量最多的类作为名字）\n",
    "            node = self.TreeNode(sub_df[self.label].iloc[0])\n",
    "            # -> 将其连接到 parent_node\n",
    "            parent_node.connect(parent_label, node)\n",
    "            return None\n",
    "\n",
    "        # 3. 正常情况：\n",
    "        #    -> 创建一个新的内部结点 (名字是 best_feature)\n",
    "        node = self.TreeNode(best_col)\n",
    "        #    -> 将其连接到 parent_node\n",
    "        parent_node.connect(parent_label, node)\n",
    "\n",
    "        # 4. 递归生成子树：\n",
    "        #    -> 计算剩余特征 (new_columns = columns - best_feature)\n",
    "        new_columns = [col for col in columns if col != best_col]\n",
    "        #    -> 遍历 max_splited 中的每一个子集 (split_value, split_data)：\n",
    "        #       调用 self.construct(当前结点, split_value, split_data, new_columns)\n",
    "        for splited_value, splited_data in max_splited.items():\n",
    "            self.construct(node, splited_value, splited_data, new_columns)\n",
    "\n",
    "    def print_tree(self, node, tabs):\n",
    "        print(tabs + node.name)\n",
    "        for connection, child_node in node.connections.items():\n",
    "            print(tabs + \"\\t\" + \"(\" + connection + \")\")\n",
    "            self.print_tree(child_node, tabs + \"\\t\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83a17f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"}\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/w0330t/machine_learning_code_implementation/refs/heads/master/charpter7_decision_tree/example_data.csv', dtype={'windy': 'str'},)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9444d8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree1 = ID3Tree(df, 'play')\n",
    "tree1.construct_tree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0228f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root\n",
      "\t()\n",
      "\t\toutlook\n",
      "\t\t\t(sunny)\n",
      "\t\t\t\thumility\n",
      "\t\t\t\t\t(high)\n",
      "\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t(hot)\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(false)\n",
      "\t\t\t\t\t\t\t\t\t\tno\n",
      "\t\t\t\t\t\t\t\t\t(true)\n",
      "\t\t\t\t\t\t\t\t\t\tno\n",
      "\t\t\t\t\t\t\t(mild)\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(false)\n",
      "\t\t\t\t\t\t\t\t\t\tno\n",
      "\t\t\t\t\t(normal)\n",
      "\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t(cool)\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(false)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t\t\t(mild)\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(true)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t(overcast)\n",
      "\t\t\t\thumility\n",
      "\t\t\t\t\t(high)\n",
      "\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t(hot)\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(false)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t\t\t(mild)\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(true)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t(normal)\n",
      "\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t(cool)\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(true)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t\t\t(hot)\n",
      "\t\t\t\t\t\t\t\twindy\n",
      "\t\t\t\t\t\t\t\t\t(false)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t(rainy)\n",
      "\t\t\t\twindy\n",
      "\t\t\t\t\t(false)\n",
      "\t\t\t\t\t\thumility\n",
      "\t\t\t\t\t\t\t(high)\n",
      "\t\t\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t\t\t(mild)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t\t\t(normal)\n",
      "\t\t\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t\t\t(cool)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t\t\t\t\t(mild)\n",
      "\t\t\t\t\t\t\t\t\t\tyes\n",
      "\t\t\t\t\t(true)\n",
      "\t\t\t\t\t\thumility\n",
      "\t\t\t\t\t\t\t(normal)\n",
      "\t\t\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t\t\t(cool)\n",
      "\t\t\t\t\t\t\t\t\t\tno\n",
      "\t\t\t\t\t\t\t(high)\n",
      "\t\t\t\t\t\t\t\ttemp\n",
      "\t\t\t\t\t\t\t\t\t(mild)\n",
      "\t\t\t\t\t\t\t\t\t\tno\n"
     ]
    }
   ],
   "source": [
    "tree1.print_tree(tree1.root, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eee96c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-code-implementation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

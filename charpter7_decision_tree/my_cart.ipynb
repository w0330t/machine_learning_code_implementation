{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b33f343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from typing import Tuple, Union, Optional, List, Any, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5145e2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gini(y: np.ndarray) -> float:\n",
    "    \"\"\"计算基尼指数\n",
    "\n",
    "    公式：Gini(p) = 1 - sum(p_k^2)\n",
    "\n",
    "    Args:\n",
    "        y (np.ndarray): 标签列表 (shape: (n_samples,))\n",
    "    Returns:\n",
    "        float: 基尼指数\n",
    "    \"\"\"\n",
    "    y = y.tolist()\n",
    "    # 1. 获取各类别的概率分布\n",
    "    probs = [y.count(i)/len(y) for i in set(y)]\n",
    "    # 2. 计算 1 - 概率平方和\n",
    "    return 1 - np.sum(np.array(probs) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8966ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_split(X: np.ndarray, feature_i: int, threshold: float) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"根据特征和阈值，将数据集拆分为两个子集\n",
    "\n",
    "    CART 是二叉树，所以只返回两个子集：\n",
    "    - left: 特征值 >= threshold (或 <，具体看你约定)\n",
    "    - right: 特征值 < threshold (或 >=)\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): 数据集(二维数组)\n",
    "        feature_i (int): 特征索引\n",
    "        threshold (float): 分裂阈值\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray]: (X_left, X_right)\n",
    "    \"\"\"\n",
    "    x_left = X[X[:, feature_i] <= threshold]\n",
    "    x_right = X[X[:, feature_i] > threshold]\n",
    "    return x_left,x_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8adc34c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode:\n",
    "    def __init__(self,\n",
    "                 depth: Optional[int] = 0,\n",
    "                 feature_i: Optional[int] = None,\n",
    "                 threshold: Optional[float] = None,\n",
    "                 leaf_value: Optional[Any] = None,\n",
    "                 left_branch: Optional['TreeNode'] = None,\n",
    "                 right_branch: Optional['TreeNode'] = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            feature_i: 切分特征的索引 (仅内部结点需要)\n",
    "            threshold: 切分阈值 (仅内部结点需要)\n",
    "            leaf_value: 叶子结点的预测值 (仅叶子结点需要)\n",
    "            left_branch: 左子树，递归 TreeNode\n",
    "            right_branch: 右子树，递归 TreeNode\n",
    "        \"\"\"\n",
    "        self.depth = depth\n",
    "        self.feature_i = feature_i\n",
    "        self.threshold = threshold\n",
    "        self.leaf_value = leaf_value\n",
    "        self.left_branch = left_branch\n",
    "        self.right_branch = right_branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bd818e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryDecisionTree:\n",
    "    def __init__(self,\n",
    "                 min_samples_split: int = 2,\n",
    "                 min_gini_impurity: float = float(\"inf\"),\n",
    "                 max_depth: float = float(\"inf\"),\n",
    "                 loss: Any = None):\n",
    "\n",
    "        self.root: Optional[TreeNode] = None  # 根结点\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_gini_impurity = min_gini_impurity\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "        # 下面这两个函数将在子类(ClassificationTree)中定义\n",
    "        self._impurity_calculation = None # 也就是 calculate_gini\n",
    "        self._leaf_value_calculation = None # 也就是 majority_vote\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"训练入口\"\"\"\n",
    "        # 拼接 X 和 y，方便统一处理\n",
    "        self.root = self._build_tree(X, y)\n",
    "\n",
    "\n",
    "    def _build_tree(self, X: np.ndarray, y: np.ndarray, current_depth: int = 0) -> TreeNode:\n",
    "        \"\"\"递归构建决策树 (核心函数)\n",
    "\n",
    "        Args:\n",
    "            X (np.ndarray): 训练数据\n",
    "            y (np.ndarray): 训练数据的标签\n",
    "            current_depth (int, optional): _description_. Defaults to 0.\n",
    "\n",
    "        Returns:\n",
    "            TreeNode: _description_\n",
    "        \"\"\"\n",
    "        Xy = np.hstack([X, y])\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # --- 步骤 1: 检查停止条件 (预剪枝) ---\n",
    "        # 如果样本数 < min_samples_split，或者深度 >= max_depth\n",
    "        # -> 直接返回叶子结点 (计算当前 y 的 leaf_value)\n",
    "        if n_samples < self.min_samples_split or \\\n",
    "           current_depth >= self.max_depth or \\\n",
    "           len(np.unique(y)) == 1:\n",
    "            return TreeNode(\n",
    "                depth=current_depth,\n",
    "                leaf_value=self._leaf_value_calculation(y)\n",
    "            )\n",
    "\n",
    "        # --- 步骤 2: 寻找最佳切分点 ---\n",
    "        best_impurity = float(\"inf\")\n",
    "        best_criteria = {} # 存 {'feature_i': ?, 'threshold': ?}\n",
    "        best_sets = {}     # 存 (left_dataset, right_dataset)\n",
    "\n",
    "        # 遍历所有特征 feature_i:\n",
    "        for i in range(n_features):\n",
    "            # 获取该特征所有的唯一值作为候选阈值 thresholds\n",
    "            thresholds = np.unique(X[:, i])\n",
    "\n",
    "            # 遍历所有 threshold:\n",
    "            for threshold in thresholds:\n",
    "                # 1. 用 feature_split 切分数据得到 Xy1, Xy2\n",
    "                Xy1, Xy2 = feature_split(Xy, i, threshold)\n",
    "\n",
    "                # 2. 如果切分后的子集不为空:\n",
    "                if len(Xy1) == 0 or len(Xy2) == 0:\n",
    "                    continue\n",
    "                # 计算加权基尼指数 (impurity)\n",
    "                impurity = self._impurity_calculation(y, Xy1[:, -1], Xy2[:, -1])\n",
    "                # 如果 impurity < best_impurity:\n",
    "                if impurity < best_impurity:\n",
    "                    # 更新 best_impurity, best_criteria, best_sets\n",
    "                    best_impurity = impurity\n",
    "                    best_criteria = {'feature_i': i, 'threshold': threshold}\n",
    "                    best_sets = {\n",
    "                        'left_X': Xy1[:, :-1],\n",
    "                        'left_y': Xy1[:, -1],\n",
    "                        'right_X': Xy2[:, :-1],\n",
    "                        'right_y': Xy2[:, -1],\n",
    "                    }\n",
    "\n",
    "\n",
    "        # --- 步骤 3: 递归构建 ---\n",
    "        # 如果计算出的 best_impurity 依然很大 (大于 min_gini_impurity) -> 不分了，返回叶子结点\n",
    "        if best_impurity > self.min_gini_impurity:\n",
    "            return TreeNode(depth=current_depth,leaf_value=self._leaf_value_calculation(y))\n",
    "        # 否则，递归构建左右子树\n",
    "        else:\n",
    "            self.min_gini_impurity = best_impurity\n",
    "            left_branch = self._build_tree(best_sets['left_X'], best_sets['left_y'].reshape(-1, 1), current_depth + 1)\n",
    "            right_branch = self._build_tree(best_sets['right_X'], best_sets['right_y'].reshape(-1, 1), current_depth + 1)\n",
    "            # 返回中间结点 (TreeNode)\n",
    "            return TreeNode(feature_i=best_criteria[\"feature_i\"],\n",
    "                            threshold=best_criteria[\"threshold\"],\n",
    "                            left_branch=left_branch,\n",
    "                            right_branch=right_branch,\n",
    "                            depth=current_depth)\n",
    "\n",
    "\n",
    "    def predict_value(self, x: np.ndarray, tree: Optional[TreeNode] = None) -> Any:\n",
    "        \"\"\"递归检索单条样本的预测值\n",
    "\n",
    "        Args:\n",
    "            x (np.ndarray): _description_\n",
    "            tree (Optional[TreeNode], optional): _description_. Defaults to None.\n",
    "\n",
    "        Returns:\n",
    "            Any: _description_\n",
    "        \"\"\"\n",
    "\n",
    "        tree = self.root if tree is None else tree\n",
    "        # print(tree.depth)\n",
    "        # 如果是叶子结点 (leaf_value is not None) -> 返回 leaf_value\n",
    "        if tree.leaf_value is not None:\n",
    "            return tree.leaf_value\n",
    "        # 否则 -> 根据 x[feature_i] 和 threshold 决定去左子树还是右子树\n",
    "        else:\n",
    "            tree = tree.left_branch if x[tree.feature_i] <= tree.threshold else tree.right_branch\n",
    "\n",
    "            return self.predict_value(x, tree)\n",
    "\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> List[Any]:\n",
    "        \"\"\"预测多条样本\"\"\"\n",
    "        return [self.predict_value(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b66c2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationTree(BinaryDecisionTree):\n",
    "    def _calculate_gini_impurity(self, y: np.ndarray, y1: np.ndarray, y2: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        计算切分后的加权基尼指数\n",
    "        Args:\n",
    "            y: 切分前的标签\n",
    "            y1: 切分后左子树的标签\n",
    "            y2: 切分后右子树的标签\n",
    "        \"\"\"\n",
    "        left_weight = len(y1)/len(y)\n",
    "        right_weight = len(y2)/len(y)\n",
    "        left_gini = calculate_gini(y1)\n",
    "        right_gini = calculate_gini(y2)\n",
    "        return left_weight * left_gini + right_weight * right_gini\n",
    "\n",
    "    def _majority_vote(self, y: np.ndarray) -> Any:\n",
    "        \"\"\"\n",
    "        多数投票（定义叶子结点的值）\n",
    "        返回 y 中出现次数最多的类别\n",
    "        \"\"\"\n",
    "        c = Counter(y.flatten())\n",
    "        return c.most_common(1)[0][0]\n",
    "\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        self._impurity_calculation = self._calculate_gini_impurity\n",
    "        self._leaf_value_calculation = self._majority_vote\n",
    "        super(ClassificationTree, self).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d58ad7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressionTree(BinaryDecisionTree):\n",
    "\n",
    "    def _calculate_variance_reduction(self, y: np.ndarray, y1: np.ndarray, y2: np.ndarray) -> float:\n",
    "        \"\"\"计算方差减少量\n",
    "        公式：Var_reduction = Var(y) - ( frac_1 * Var(y1) + frac_2 * Var(y2) )\n",
    "\n",
    "        Args:\n",
    "            y (np.ndarray): 切分前的标签\n",
    "            y1 (np.ndarray): 切分后左子树的标签\n",
    "            y2 (np.ndarray): 切分后右子树的标签\n",
    "\n",
    "        Returns:\n",
    "            float: 方差减少量\n",
    "        \"\"\"\n",
    "        frac_1 = len(y1)/len(y)\n",
    "        frac_2 = len(y2)/len(y)\n",
    "        var_reduction = ( frac_1 * np.var(y1) + frac_2 * np.var(y2) )\n",
    "        return var_reduction\n",
    "\n",
    "    def _mean_of_y(self, y: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        计算叶子结点的预测值\n",
    "        回归树直接返回当前节点标签 y 的平均值\n",
    "        \"\"\"\n",
    "        return np.mean(y)\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        训练模型\n",
    "        继承函数，并将上述两个函数注册到基类中\n",
    "        \"\"\"\n",
    "        self._impurity_calculation = self._calculate_variance_reduction\n",
    "        self._leaf_value_calculation = self._mean_of_y\n",
    "        super(RegressionTree, self).fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9af831fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "data = datasets.load_iris()\n",
    "X, y = data.data, data.target\n",
    "# 注意！是否要对y进行reshape取决于numpy版本\n",
    "y = y.reshape(-1,1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "clf = ClassificationTree()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4467d223",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: \"\\s\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\s\"? A raw string is also an option.\n",
      "<>:7: SyntaxWarning: \"\\s\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\s\"? A raw string is also an option.\n",
      "/tmp/ipykernel_1214776/1778655665.py:7: SyntaxWarning: \"\\s\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\s\"? A raw string is also an option.\n",
      "  raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 28.974363518590916\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 波士顿房价数据集的原始 URL\n",
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "\n",
    "# 从 URL 加载数据\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
    "\n",
    "# 处理数据\n",
    "data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])  # 拼接特征数据\n",
    "target = raw_df.values[1::2, 2]  # 目标变量\n",
    "\n",
    "# 将数据和目标变量转换为 NumPy 数组\n",
    "X = np.array(data)\n",
    "y = np.array(target)\n",
    "\n",
    "y = y.reshape(-1,1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "model = RegressionTree()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b7e7b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine-learning-code-implementation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
